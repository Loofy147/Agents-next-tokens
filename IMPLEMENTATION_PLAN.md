# T4 Implementation Plan: Foundational World Model

This document outlines the step-by-step plan for implementing the T4 Foundational World Model, as defined in `ROADMAP.md`.

## 1. De-scoping and Component Removal

*   **Objective:** Simplify the existing `hiro_agent.py` to create a clean foundation for the new architecture.
*   **Rationale:** The T4 architecture represents a significant paradigm shift. Removing outdated T2/T3 components will streamline the codebase, reduce complexity, and prevent legacy code from interfering with the new world model.
*   **Action Items:**
    *   Remove the `InverseModel` class, as the world model will directly handle latent state representation.
    *   Remove the `SubgoalDiffuser`, which will be replaced by the Transformer-based planner.
    *   Remove the existing `CausalEmpowerment` module, as a more advanced causal discovery mechanism will be introduced in T5.
    *   Delete the `T3Config` dataclass and create a new `T4Config` to reflect the updated hyperparameters.

## 2. Introduce the Transformer-Based World Model

*   **Objective:** Implement the core of the T4 agent: a sophisticated, Transformer-based world model.
*   **Rationale:** This model will be responsible for learning a predictive model of the environment's dynamics in a compressed latent space, forming the foundation for planning and decision-making.
*   **Action Items:**
    *   **Implement a Discrete Autoencoder:**
        *   Create an `Encoder` module to map raw observations to a sequence of discrete latent variables (similar to a VQ-VAE).
        *   Create a `Decoder` module to reconstruct observations from the latent state, enabling self-supervised training.
    *   **Implement the Transformer Model:**
        *   Create a `Transformer` class (e.g., `WorldModel`) that takes the discrete latent state as input.
        *   This model will be trained to auto-regressively predict the next latent state, thereby learning the environment's dynamics.

## 3. Implement the Actor-Critic Planner

*   **Objective:** Create a planner that can operate entirely within the latent space of the world model.
*   **Rationale:** By planning in "imagination," the agent can explore potential futures without costly interaction with the real environment, dramatically improving sample efficiency.
*   **Action Items:**
    *   **Create an `Actor` Network:**
        *   This network will take a latent state from the world model as input and predict a sequence of actions.
    *   **Create a `Critic` Network:**
        *   This network will evaluate the sequence of latent states produced by the actor, predicting the expected return.
    *   **Integrate with the World Model:**
        *   The actor and critic will be trained on trajectories generated by rolling out the world model in latent space.

## 4. Refactor the Main Training Loop

*   **Objective:** Update the main training loop in `hiro_agent.py` to orchestrate the new T4 components.
*   **Rationale:** The existing training loop is designed for the old T2/T3 architecture and must be adapted for the new world model-centric approach.
*   **Action Items:**
    *   Replace the existing `T3_Agent` class with a new `T4_Agent` class.
    *   Implement the main training phases:
        1.  **World Model Training:** Train the discrete autoencoder and the Transformer on collected experience.
        2.  **Actor-Critic Training:** Train the actor and critic on imagined trajectories from the world model.
        3.  **Environment Interaction:** Use the trained actor to select actions in the real environment to collect new experience.
    *   Update the `run_evaluation` function to properly instantiate and run the `T4_Agent`.
